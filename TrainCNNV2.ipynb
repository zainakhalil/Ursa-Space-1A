{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQhyZrb2TP_-"
   },
   "source": [
    "The notebook mounts Google Drive, reads train.json from “Ursa Space 1A,” and converts each sample’s band_1 and band_2 lists into 75×75 float images, stacked as a two-channel tensor [N, 2, 75, 75]. Labels (is_iceberg) and incidence angles are loaded; angles are imputed with the train-set median for missing values and optionally z-normalized. A stratified 80/20 split creates train/validation indices. Per-channel statistics (mean, std) are computed on the train tensor and used to z-normalize both splits; all arrays plus angles are saved to a compact artifact sar_fullres_splits.npz for reproducibility. The model IcebergVesselCNN is a compact convolutional trunk (Conv-ReLU-MaxPool blocks → AdaptiveAvgPool to a 128-d feature) with an angle-fusion head that concatenates the (optionally normalized) angle to the pooled feature before a small MLP classifier. Training uses AdamW with cross-entropy loss, optional mixed precision (AMP), light SAR-appropriate augmentations (random horizontal/vertical flips and 90° rotations), and a ReduceLROnPlateau scheduler keyed to validation AUC, with early stopping based on AUC to prevent overfitting. After each epoch, accuracy and AUC are computed on the validation set and the best checkpoint is stored as best_iceberg_vessel_cnn.pt. Final reporting includes accuracy, ROC-AUC, and a confusion matrix (e.g., TN/FP/FN/TP), confirming strong performance on the iceberg-vs-vessel classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 533,
     "status": "ok",
     "timestamp": 1760979017192,
     "user": {
      "displayName": "Zaina Khalil",
      "userId": "08515068669285487272"
     },
     "user_tz": 300
    },
    "id": "Qk-BQ8P7KT2s",
    "outputId": "56cf9758-bef5-421c-a890-7051e45b5c9f"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2209,
     "status": "ok",
     "timestamp": 1760979121886,
     "user": {
      "displayName": "Zaina Khalil",
      "userId": "08515068669285487272"
     },
     "user_tz": 300
    },
    "id": "vh85WN-sgPxE",
    "outputId": "1b2006f6-395f-49e3-b8c3-14473ee7194e"
   },
   "outputs": [],
   "source": [
    "# go into the repo you already have\n",
    "%cd /content/Ursa-Space-1A\n",
    "\n",
    "# (optional) see remotes/branch status\n",
    "!git remote -v\n",
    "!git branch --show-current\n",
    "\n",
    "# if you need to set the push URL with your token:\n",
    "from google.colab import userdata\n",
    "import os\n",
    "os.environ[\"GITHUB_TOKEN\"] = userdata.get(\"GITHUB_TOKEN\")  # token must exist and have repo scope\n",
    "!git remote set-url --push origin https://x-access-token:${GITHUB_TOKEN}@github.com/zainakhalil/Ursa-Space-1A.git\n",
    "\n",
    "# copy any files in (example: move train.py you generated)\n",
    "!cp /mnt/data/train.py .\n",
    "\n",
    "# commit & push\n",
    "!git add -A\n",
    "!git commit -m \"Add cleaned training script\"\n",
    "!git push origin HEAD:main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 101,
     "status": "ok",
     "timestamp": 1760978605603,
     "user": {
      "displayName": "Zaina Khalil",
      "userId": "08515068669285487272"
     },
     "user_tz": 300
    },
    "id": "AE_-LW6RcJ63"
   },
   "outputs": [],
   "source": [
    "# Add All Changes\n",
    "!git add \"TrainCNNV2.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 818,
     "status": "ok",
     "timestamp": 1760978607402,
     "user": {
      "displayName": "Zaina Khalil",
      "userId": "08515068669285487272"
     },
     "user_tz": 300
    },
    "id": "pBXbpc0wel-h"
   },
   "outputs": [],
   "source": [
    "# Replace 'Your_Notebook_Name.ipynb' with the actual name of your notebook file\n",
    "!cp \"/content/drive/MyDrive/Colab Notebooks/TrainCNNV2.ipynb\" \"/content/Ursa-Space-1A/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 112,
     "status": "ok",
     "timestamp": 1760978608512,
     "user": {
      "displayName": "Zaina Khalil",
      "userId": "08515068669285487272"
     },
     "user_tz": 300
    },
    "id": "G9x6OkCQerOp",
    "outputId": "0e4e1db0-f310-4a46-dc0a-f04fc1381ffe"
   },
   "outputs": [],
   "source": [
    "# Commit Changes\n",
    "!git commit -m \"Train CNN Attempt 2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1760978610398,
     "user": {
      "displayName": "Zaina Khalil",
      "userId": "08515068669285487272"
     },
     "user_tz": 300
    },
    "id": "YSC8xOsFe44z"
   },
   "outputs": [],
   "source": [
    "!git config --global user.email \"zkhal4@uic.edu\"\n",
    "!git config --global user.name \"zainakhalil\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 712,
     "status": "ok",
     "timestamp": 1760978613445,
     "user": {
      "displayName": "Zaina Khalil",
      "userId": "08515068669285487272"
     },
     "user_tz": 300
    },
    "id": "zUaCtIKCe764",
    "outputId": "e8647511-2ebd-4faa-949f-d6b77735b678"
   },
   "outputs": [],
   "source": [
    "# Push to the Remote Repository\n",
    "!git push origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4224,
     "status": "ok",
     "timestamp": 1760973251578,
     "user": {
      "displayName": "Zaina Khalil",
      "userId": "08515068669285487272"
     },
     "user_tz": 300
    },
    "id": "y2tnLJgYKaVn",
    "outputId": "4d1da594-24a6-41ec-bd4a-467259a0923e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "!ls \"/content/drive/MyDrive/Ursa Space 1A/train.json\"\n",
    "df = pd.read_json('/content/drive/MyDrive/Ursa Space 1A/train.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11660,
     "status": "ok",
     "timestamp": 1760973373360,
     "user": {
      "displayName": "Zaina Khalil",
      "userId": "08515068669285487272"
     },
     "user_tz": 300
    },
    "id": "MZim7rvJJdUr",
    "outputId": "9392560a-0b17-416f-f3ff-2fe64e3425bd"
   },
   "outputs": [],
   "source": [
    "import math, numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path(\"/content/drive/MyDrive/Ursa Space 1A/train.json\")\n",
    "ART_DIR   = Path(\"/content/artifacts\"); ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df = pd.read_json(DATA_PATH)\n",
    "\n",
    "def to_img(seq):\n",
    "    a = np.array(seq, dtype=np.float32)\n",
    "    side = int(round(math.sqrt(a.size)))\n",
    "    assert side*side == a.size, f\"Non-square band length {a.size}\"\n",
    "    return a.reshape(side, side)\n",
    "\n",
    "# [N, 2, H, W]  (two channels: band_1, band_2)\n",
    "X = np.stack([np.stack([to_img(b1), to_img(b2)], axis=0)\n",
    "              for b1, b2 in zip(df[\"band_1\"], df[\"band_2\"])], axis=0)\n",
    "y = df[\"is_iceberg\"].astype(np.int64).to_numpy()\n",
    "inc_angle = pd.to_numeric(df[\"inc_angle\"], errors=\"coerce\").to_numpy()\n",
    "\n",
    "# stratified 80/20 split\n",
    "idx = np.arange(len(y))\n",
    "idx_tr, idx_va = train_test_split(idx, test_size=0.2, random_state=1234, stratify=y)\n",
    "X_tr, X_va = X[idx_tr], X[idx_va]\n",
    "y_tr, y_va = y[idx_tr], y[idx_va]\n",
    "ang_tr, ang_va = inc_angle[idx_tr], inc_angle[idx_va]\n",
    "\n",
    "# per-channel z-normalization using train stats\n",
    "m = X_tr.mean(axis=(0,2,3), keepdims=True)\n",
    "s = X_tr.std(axis=(0,2,3), keepdims=True) + 1e-6\n",
    "X_tr = (X_tr - m)/s\n",
    "X_va = (X_va - m)/s\n",
    "\n",
    "np.savez_compressed(ART_DIR / \"sar_fullres_splits.npz\",\n",
    "    X_train=X_tr, y_train=y_tr, X_val=X_va, y_val=y_va,\n",
    "    means=m.squeeze(), stds=s.squeeze(), side=int(X.shape[-1]),\n",
    "    inc_angle_train=ang_tr, inc_angle_val=ang_va\n",
    ")\n",
    "X_tr.shape, X_va.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 64055,
     "status": "ok",
     "timestamp": 1760973461784,
     "user": {
      "displayName": "Zaina Khalil",
      "userId": "08515068669285487272"
     },
     "user_tz": 300
    },
    "id": "ZNhSmZRTMYwK",
    "outputId": "807c61d2-c461-403f-d4d6-ff3e37cf3ccc"
   },
   "outputs": [],
   "source": [
    "import numpy as np, torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "data = np.load(\"/content/artifacts/sar_fullres_splits.npz\")\n",
    "Xtr, Xva = data[\"X_train\"], data[\"X_val\"]\n",
    "ytr, yva = data[\"y_train\"], data[\"y_val\"]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "Xtr_t = torch.tensor(Xtr, dtype=torch.float32)\n",
    "Xva_t = torch.tensor(Xva, dtype=torch.float32)\n",
    "ytr_t = torch.tensor(ytr, dtype=torch.long)\n",
    "yva_t = torch.tensor(yva, dtype=torch.long)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(Xtr_t, ytr_t), batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(TensorDataset(Xva_t, yva_t), batch_size=128, shuffle=False)\n",
    "\n",
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self, in_ch=2, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, 16, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "        )\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = self.net(x).view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "model = SmallCNN().to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "def run_epoch(dl, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    tot=correct=loss_sum=0\n",
    "    for xb,yb in dl:\n",
    "        xb,yb = xb.to(device), yb.to(device)\n",
    "        if train: opt.zero_grad()\n",
    "        with torch.set_grad_enabled(train):\n",
    "            logits = model(xb); loss = crit(logits, yb)\n",
    "            if train: loss.backward(); opt.step()\n",
    "        pred = logits.argmax(1)\n",
    "        correct += (pred==yb).sum().item()\n",
    "        tot += yb.numel(); loss_sum += loss.item()*yb.size(0)\n",
    "    return loss_sum/tot, correct/tot\n",
    "\n",
    "for ep in range(8):\n",
    "    tr_loss,tr_acc = run_epoch(train_loader, True)\n",
    "    va_loss,va_acc = run_epoch(val_loader, False)\n",
    "    print(f\"Epoch {ep+1}: tr {tr_loss:.4f}/{tr_acc:.3f} | va {va_loss:.4f}/{va_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1760973915175,
     "user": {
      "displayName": "Zaina Khalil",
      "userId": "08515068669285487272"
     },
     "user_tz": 300
    },
    "id": "VNQMvn5KOT98",
    "outputId": "c5f68a49-c125-4c2d-cc35-e6362f28902d"
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# Config Small CNN + Small Utilities\n",
    "# ==================================\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Paths\n",
    "    npz_path: str = \"/content/artifacts/sar_fullres_splits.npz\"\n",
    "    save_dir: str = \"/content/artifacts\"\n",
    "    # Training\n",
    "    batch_size: int = 64\n",
    "    epochs: int = 20\n",
    "    lr: float = 1e-3\n",
    "    weight_decay: float = 1e-4\n",
    "    # Early stopping / LR schedule\n",
    "    patience: int = 5          # epochs with no AUC improvement to stop\n",
    "    lr_patience: int = 2       # plateaus before LR reduce\n",
    "    lr_gamma: float = 0.5\n",
    "    # Augmentations\n",
    "    hflip_p: float = 0.5\n",
    "    vflip_p: float = 0.5\n",
    "    rot90_p: float = 0.5       # random k*90° rotation\n",
    "    # Incidence angle fusion\n",
    "    use_angle: bool = True     # set False to ignore angle\n",
    "    norm_angle: bool = True    # z-norm angle using train stats\n",
    "\n",
    "cfg = Config()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "Path(cfg.save_dir).mkdir(parents=True, exist_ok=True)\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 708,
     "status": "ok",
     "timestamp": 1760973950331,
     "user": {
      "displayName": "Zaina Khalil",
      "userId": "08515068669285487272"
     },
     "user_tz": 300
    },
    "id": "t69VltVVOdBV"
   },
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Load NPZ + Prepare Tensors\n",
    "# ===========================\n",
    "D = np.load(cfg.npz_path)\n",
    "\n",
    "Xtr = D[\"X_train\"]          # [N, 2, 75, 75]\n",
    "Xva = D[\"X_val\"]\n",
    "ytr = D[\"y_train\"].astype(np.int64)\n",
    "yva = D[\"y_val\"].astype(np.int64)\n",
    "\n",
    "# Angle arrays can have NaN; we'll impute with train median, then optionally z-norm\n",
    "if cfg.use_angle:\n",
    "    ang_tr = D[\"inc_angle_train\"].astype(np.float32)\n",
    "    ang_va = D[\"inc_angle_val\"].astype(np.float32)\n",
    "\n",
    "    # Impute missing angles with train median (robust/simple)\n",
    "    train_med = np.nanmedian(ang_tr)\n",
    "    ang_tr = np.where(np.isfinite(ang_tr), ang_tr, train_med)\n",
    "    ang_va = np.where(np.isfinite(ang_va), ang_va, train_med)\n",
    "\n",
    "    if cfg.norm_angle:\n",
    "        mu, sd = ang_tr.mean(), ang_tr.std() + 1e-6\n",
    "        ang_tr = (ang_tr - mu) / sd\n",
    "        ang_va = (ang_va - mu) / sd\n",
    "else:\n",
    "    ang_tr = np.zeros(len(ytr), dtype=np.float32)\n",
    "    ang_va = np.zeros(len(yva), dtype=np.float32)\n",
    "\n",
    "# ---------------------------\n",
    "# PyTorch Tensor Conversion\n",
    "# ---------------------------\n",
    "Xtr_t = torch.tensor(Xtr, dtype=torch.float32)\n",
    "Xva_t = torch.tensor(Xva, dtype=torch.float32)\n",
    "ytr_t = torch.tensor(ytr, dtype=torch.long)\n",
    "yva_t = torch.tensor(yva, dtype=torch.long)\n",
    "ang_tr_t = torch.tensor(ang_tr, dtype=torch.float32).view(-1, 1)\n",
    "ang_va_t = torch.tensor(ang_va, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# ---------------------------\n",
    "# Lightweight Augmentations\n",
    "# ---------------------------\n",
    "# We implement custom tensor-based flips/rotations (works for 2-channel SAR)\n",
    "import random\n",
    "\n",
    "def aug_batch(xb):\n",
    "    \"\"\"Apply in-place random flips/rot90 to a batch of images [B,2,H,W].\"\"\"\n",
    "    B = xb.size(0)\n",
    "    for i in range(B):\n",
    "        if random.random() < cfg.hflip_p:\n",
    "            xb[i] = torch.flip(xb[i], dims=[2])  # horizontal flip (W axis)\n",
    "        if random.random() < cfg.vflip_p:\n",
    "            xb[i] = torch.flip(xb[i], dims=[1])  # vertical flip (H axis)\n",
    "        if random.random() < cfg.rot90_p:\n",
    "            k = random.randint(1,3)\n",
    "            xb[i] = torch.rot90(xb[i], k, dims=[1,2])  # rotate k*90°\n",
    "    return xb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1760973967784,
     "user": {
      "displayName": "Zaina Khalil",
      "userId": "08515068669285487272"
     },
     "user_tz": 300
    },
    "id": "PAlFFgkKOhaL"
   },
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# CNN with Angle Fusion\n",
    "# ===========================\n",
    "class IcebergVesselCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A compact CNN trunk for 2-channel SAR (band_1, band_2) + optional angle fusion.\n",
    "    Trunk: Conv -> ReLU -> Pool x3 + GlobalAvgPool -> feature vector (64 dims)\n",
    "    Head:  If use_angle, concat [feat, angle] -> Linear -> logits(2)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch=2, use_angle=True):\n",
    "        super().__init__()\n",
    "        self.use_angle = use_angle\n",
    "        self.trunk = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, 32, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 75->37\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 37->18\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 18->9\n",
    "            nn.Conv2d(128, 128, 3, padding=1), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1),          # -> [B,128,1,1]\n",
    "        )\n",
    "        feat_dim = 128\n",
    "        head_in = feat_dim + (1 if use_angle else 0)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(head_in, 64), nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, angle=None):\n",
    "        f = self.trunk(x).view(x.size(0), -1)  # [B,128]\n",
    "        if self.use_angle:\n",
    "            assert angle is not None, \"Angle tensor is required when use_angle=True\"\n",
    "            f = torch.cat([f, angle], dim=1)   # [B,129]\n",
    "        return self.head(f)\n",
    "\n",
    "model = IcebergVesselCNN(in_ch=2, use_angle=cfg.use_angle).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 422616,
     "status": "ok",
     "timestamp": 1760974783722,
     "user": {
      "displayName": "Zaina Khalil",
      "userId": "08515068669285487272"
     },
     "user_tz": 300
    },
    "id": "3QYHIXCOOlxq",
    "outputId": "25f75908-26bd-4bf6-e5d5-ad69c2f903ef"
   },
   "outputs": [],
   "source": [
    "import numpy as np, torch\n",
    "from torch.amp import autocast, GradScaler  # new API (works on Colab)\n",
    "# If your torch is older, fallback:\n",
    "# from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "use_amp = torch.cuda.is_available()\n",
    "scaler  = GradScaler('cuda' if use_amp else 'cpu')\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    \"\"\"One epoch. Returns (avg_loss, accuracy, auc).\"\"\"\n",
    "    model.train() if train else model.eval()\n",
    "    losses, preds_all, probs_all, ys_all = [], [], [], []\n",
    "\n",
    "    for xb, ab, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        ab = ab.to(device) if cfg.use_angle else None\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        if train:\n",
    "            # ---- forward with (optional) autocast\n",
    "            with autocast(device_type='cuda', enabled=use_amp):\n",
    "                logits = model(xb, ab) if cfg.use_angle else model(xb)\n",
    "                loss   = criterion(logits, yb)\n",
    "\n",
    "            # ---- backward + step (AMP or not)\n",
    "            if use_amp:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                logits = model(xb, ab) if cfg.use_angle else model(xb)\n",
    "                loss   = criterion(logits, yb)\n",
    "\n",
    "        # ---- bookkeeping\n",
    "        losses.append(loss.item())\n",
    "        prob = torch.softmax(logits, dim=1)[:, 1].detach().cpu().numpy()\n",
    "        pred = (prob >= 0.5).astype(np.int64)\n",
    "        y_np = yb.detach().cpu().numpy()\n",
    "        probs_all.append(prob); preds_all.append(pred); ys_all.append(y_np)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "    y_true = np.concatenate(ys_all)\n",
    "    y_prob = np.concatenate(probs_all)\n",
    "    y_pred = np.concatenate(preds_all)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_prob)\n",
    "    except Exception:\n",
    "        auc = float(\"nan\")\n",
    "    return float(np.mean(losses)), acc, auc\n",
    "\n",
    "# -------- training loop (unchanged except for using the fixed run_epoch) --------\n",
    "best_auc = 0.0\n",
    "epochs_no_improve = 0\n",
    "best_path = str(Path(cfg.save_dir) / \"best_iceberg_vessel_cnn.pt\")\n",
    "\n",
    "for ep in range(1, cfg.epochs+1):\n",
    "    tr_loss, tr_acc, tr_auc = run_epoch(train_loader, train=True)\n",
    "    va_loss, va_acc, va_auc = run_epoch(val_loader,   train=False)\n",
    "\n",
    "    if np.isfinite(va_auc):\n",
    "        scheduler.step(va_auc)\n",
    "\n",
    "    print(f\"Epoch {ep:02d} | \"\n",
    "          f\"tr loss {tr_loss:.4f} acc {tr_acc:.3f} auc {tr_auc:.3f} || \"\n",
    "          f\"va loss {va_loss:.4f} acc {va_acc:.3f} auc {va_auc:.3f}\")\n",
    "\n",
    "    if va_auc > best_auc + 1e-4:\n",
    "        best_auc = va_auc\n",
    "        epochs_no_improve = 0\n",
    "        torch.save({\"model_state\": model.state_dict(), \"cfg\": cfg.__dict__}, best_path)\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= cfg.patience:\n",
    "            print(f\"Early stopping at epoch {ep} (best val AUC={best_auc:.3f}).\")\n",
    "            break\n",
    "\n",
    "print(\"Best model saved to:\", best_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1896,
     "status": "ok",
     "timestamp": 1760974858272,
     "user": {
      "displayName": "Zaina Khalil",
      "userId": "08515068669285487272"
     },
     "user_tz": 300
    },
    "id": "ixlOs5CpQ02q",
    "outputId": "0b1a9dd4-6903-4282-c7de-975adb73f17c"
   },
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Load Best & Full Evaluation\n",
    "# ===========================\n",
    "ckpt = torch.load(best_path, map_location=device)\n",
    "model.load_state_dict(ckpt[\"model_state\"])\n",
    "model.eval()\n",
    "\n",
    "# Collect validation predictions for metrics & confusion matrix\n",
    "all_probs, all_preds, all_true = [], [], []\n",
    "with torch.no_grad():\n",
    "    for xb, ab, yb in val_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        ab = ab.to(device) if cfg.use_angle else None\n",
    "        logits = model(xb, ab) if cfg.use_angle else model(xb)\n",
    "        prob = torch.softmax(logits, dim=1)[:,1].cpu().numpy()\n",
    "        pred = (prob >= 0.5).astype(int)\n",
    "        all_probs.append(prob)\n",
    "        all_preds.append(pred)\n",
    "        all_true.append(yb.cpu().numpy())\n",
    "\n",
    "y_true = np.concatenate(all_true)\n",
    "y_prob = np.concatenate(all_probs)\n",
    "y_pred = np.concatenate(all_preds)\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "auc = roc_auc_score(y_true, y_prob)\n",
    "cm  = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(f\"Validation ACC: {acc:.3f} | AUC: {auc:.3f}\")\n",
    "print(\"Confusion matrix [[TN, FP],[FN, TP]]:\\n\", cm)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMALnaqi2xnZPDFm3TA7EAP",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
